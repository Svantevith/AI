{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Concatenate Vs Stack\n",
    "Concatenating joins a sequence of tensors along an existing axis, and stacking joins a sequence of tensors along a\n",
    "new axis.\n",
    "\n",
    "    Join Method\t    Where\n",
    "\n",
    "    · Concatenate\tAlong an existing axis\n",
    "    · Stack\t        Along a new axis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How To Add Or Insert An Axis Into A Tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([[1, 1, 1]])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1, 1, 1]) # rank=1 tensor (1d)\n",
    "print(t1.shape)\n",
    "print(t1.unsqueeze(dim=0))\n",
    "print(t1.unsqueeze(dim=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    · Unsqueeze by dim=0 (1D tensor!) -> 2D tensor with a SINGLE row (axis=0)\n",
    "    · Unsqueeze by dim=1 (1D tensor!) -> 2D tensor with number of rows, corresponding to the previous number of columns\n",
    "    (put value from each column to separate row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stack Vs Cat In PyTorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "t1 = torch.tensor([1, 1, 1])\n",
    "t2 = torch.tensor([2, 2, 2])\n",
    "t3 = torch.tensor([3, 3, 3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Concatenation happens along EXISTING axis."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 2, 2, 2, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    torch.cat(\n",
    "        tensors=(t1, t2, t3),\n",
    "        dim=0\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Stacking happens along NEW axis."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3]])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    torch.stack(\n",
    "        tensors=(t1, t2, t3),\n",
    "        dim=0\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    torch.stack(\n",
    "        tensors=(t1, t2, t3),\n",
    "        dim=1\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Stacking is basically concatenating along the added axes (unsqueeze the tensors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3]])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    torch.cat(\n",
    "        tensors=(\n",
    "            t1.unsqueeze(dim=0),\n",
    "            t2.unsqueeze(dim=0),\n",
    "            t3.unsqueeze(dim=0)\n",
    "        ),\n",
    "        dim=0\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    torch.cat(\n",
    "        tensors=(\n",
    "            t1.unsqueeze(dim=1),\n",
    "            t2.unsqueeze(dim=1),\n",
    "            t3.unsqueeze(dim=1)\n",
    "        ),\n",
    "        dim=1\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stack Vs Concat In TensorFlow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "t1 = tf.constant([1, 1, 1])\n",
    "t2 = tf.constant([2, 2, 2])\n",
    "t3 = tf.constant([3, 3, 3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 1 2 2 2 3 3 3], shape=(9,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tf.concat(\n",
    "        values=(t1, t2, t3),\n",
    "        axis=0\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 1 1]\n",
      " [2 2 2]\n",
      " [3 3 3]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tf.stack(\n",
    "        values=(t1, t2, t3),\n",
    "        axis=0\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tf.stack(\n",
    "        values=(t1, t2, t3),\n",
    "        axis=1\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again, the results are the same as the PyTorch results. Now, we'll concatenate these after manually inserting the new\n",
    "dimension."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 1 1]\n",
      " [2 2 2]\n",
      " [3 3 3]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tf.concat(\n",
    "        values=(\n",
    "            tf.expand_dims(input=t1, axis=0),\n",
    "            tf.expand_dims(input=t2, axis=0),\n",
    "            tf.expand_dims(input=t3, axis=0)\n",
    "        ),\n",
    "        axis=0\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tf.concat(\n",
    "        values=(\n",
    "            tf.expand_dims(input=t1, axis=1),\n",
    "            tf.expand_dims(input=t2, axis=1),\n",
    "            tf.expand_dims(input=t3, axis=1)\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stack Vs Concatenate In NumPy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "t1 = np.array([1, 1, 1])\n",
    "t2 = np.array([2, 2, 2])\n",
    "t3 = np.array([3, 3, 3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 2 2 2 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.concatenate(\n",
    "        (t1, t2, t3),\n",
    "        axis=0,\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 2 2 2 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.hstack(\n",
    "        (t1, t2, t3)\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [2 2 2]\n",
      " [3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.vstack(\n",
    "        (t1, t2, t3)\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.stack(\n",
    "        (t1, t2, t3),\n",
    "        axis=1\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [2 2 2]\n",
      " [3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.concatenate(\n",
    "        (np.expand_dims(t1, axis=0),\n",
    "         np.expand_dims(t2, axis=0),\n",
    "         np.expand_dims(t3, axis=0)\n",
    "         ),\n",
    "        axis=0\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.concatenate(\n",
    "        (np.expand_dims(t1, axis=1),\n",
    "         np.expand_dims(t2, axis=1),\n",
    "         np.expand_dims(t3, axis=1)\n",
    "         ),\n",
    "        axis=1\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.column_stack((t1, t2, t3)) == np.stack((t1, t2, t3), 1)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.row_stack((t1, t2, t3) == np.stack((t1, t2, t3), axis=0))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stack Or Concat: Real-Life Examples\n",
    "\n",
    "    1.  Joining Images Into A Single Batch\n",
    "    2.  Joining Batches Into A Single Batch\n",
    "    3.  Joining Images With An Existing Batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Joining Images Into A Single Batch\n",
    "uppose we have three individual images as tensors. Each image tensor has three dimensions, a channel axis, a height\n",
    "axis, a width axis. Note that each of these tensors are separate from one another. Now, assume that our task is to join\n",
    "these tensors together to form a single batch tensor of three images.\n",
    "\n",
    "    · Remember that Image is of shape (color_channels, height, width) !"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "t1 = torch.zeros(3, 28, 28) # single image containing 3 color channels being 28x28px large\n",
    "t2 = torch.zeros(3, 28, 28)\n",
    "t3 = torch.zeros(3, 28, 28)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "single_batch = torch.stack(\n",
    "    tensors=(t1, t2, t3),\n",
    "    dim=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(single_batch.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Joining Batches Into A Single Batch\n",
    "Well, notice how there is an existing dimension that we can concat on (in every batch we have a dimension for number of\n",
    "images). This means that we concat these along the batch (number of images) dimension.\n",
    "\n",
    "In this case there is no need to stack."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "t1 = torch.zeros(5, 3, 28, 28) # single batch containing single imag, 3 color channels, 28x28px\n",
    "t2 = torch.zeros(5, 3, 28, 28)\n",
    "t3 = torch.zeros(5, 3, 28, 28)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "single_batch = torch.cat(\n",
    "    tensors=(t1, t2, t3),\n",
    "    dim=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(single_batch.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Joining Images With An Existing Batch\n",
    "Do we concat or do we stack?\n",
    "\n",
    "Well, notice how the batch axis already exists inside the batch tensor. However, for the images, there is no batch axis\n",
    "in existence. This means neither of these will work. To join with stack or cat, we need the tensors to have matching\n",
    "shapes.\n",
    "\n",
    "So then, are we stuck? Is this impossible?\n",
    "\n",
    "It is indeed possible. It’s actually a very common task. The answer is to first stack and then to concat."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "single_batch = torch.zeros(10, 3, 28, 28)\n",
    "t1 = torch.zeros(3, 28, 28)\n",
    "t2 = torch.zeros(3, 28, 28)\n",
    "t3 = torch.zeros(3, 28, 28)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Firstly to create a batch of images (rank 3 tensors) we need to stack these images vertically (dim=0) to create that\n",
    "batch size dimension"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "single_batch2 = torch.stack(\n",
    "    tensors=(t1, t2, t3),\n",
    "    dim=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because we have now 2 batches, we can easily concatenate them, because they both contain the batch size dimension."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_batch = torch.cat(\n",
    "    tensors=(single_batch, single_batch2),\n",
    "    dim=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(new_batch.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}