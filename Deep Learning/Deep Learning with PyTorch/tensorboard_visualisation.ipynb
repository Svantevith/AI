{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TensorBoard: TensorFlow's Visualization Toolkit\n",
    "TensorBoard provides the visualization and tooling needed for machine learning experimentation:\n",
    "\n",
    "    · Tracking and visualizing metrics such as loss and accuracy\n",
    "    · Visualizing the model graph (ops and layers)\n",
    "    · Viewing histograms of weights, biases, or other tensors as they change over time\n",
    "    · Projecting embeddings to a lower dimensional space\n",
    "    · Displaying images, text, and audio data\n",
    "    · Profiling TensorFlow programs\n",
    "    · And much more"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from network import Network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=100,\n",
    "    shuffle=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "tb = SummaryWriter()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "network = Network()\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=network.parameters(),\n",
    "    lr=0.01\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "images, labels = next(\n",
    "    iter(train_loader)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "grid = torchvision.utils.make_grid(images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \n",
      "Total_correct: 46901 \n",
      "Total_loss: 348.6813206523657 \n",
      "Accuracy: 0.7816833333333333\n",
      "Epoch: 1 \n",
      "Total_correct: 51425 \n",
      "Total_loss: 231.83927330374718 \n",
      "Accuracy: 0.8570833333333333\n",
      "Epoch: 2 \n",
      "Total_correct: 52113 \n",
      "Total_loss: 214.81694144010544 \n",
      "Accuracy: 0.86855\n",
      "Epoch: 3 \n",
      "Total_correct: 52398 \n",
      "Total_loss: 207.53233568370342 \n",
      "Accuracy: 0.8733\n",
      "Epoch: 4 \n",
      "Total_correct: 52786 \n",
      "Total_loss: 196.99488213658333 \n",
      "Accuracy: 0.8797666666666667\n",
      "Epoch: 5 \n",
      "Total_correct: 52994 \n",
      "Total_loss: 190.42453299462795 \n",
      "Accuracy: 0.8832333333333333\n",
      "Epoch: 6 \n",
      "Total_correct: 52980 \n",
      "Total_loss: 190.9007575660944 \n",
      "Accuracy: 0.883\n",
      "Epoch: 7 \n",
      "Total_correct: 53184 \n",
      "Total_loss: 184.1041710227728 \n",
      "Accuracy: 0.8864\n",
      "Epoch: 8 \n",
      "Total_correct: 53263 \n",
      "Total_loss: 184.73317089676857 \n",
      "Accuracy: 0.8877166666666667\n",
      "Epoch: 9 \n",
      "Total_correct: 53243 \n",
      "Total_loss: 182.4922836869955 \n",
      "Accuracy: 0.8873833333333333\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    total_loss_per_epoch = 0\n",
    "    total_correct_per_epoch = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "\n",
    "        images, labels = batch # 1. Get Batch\n",
    "\n",
    "        predictions = network(images) # 2. Pass Batch into Network\n",
    "\n",
    "        loss = nn.functional.cross_entropy(\n",
    "            input=predictions,\n",
    "            target=labels\n",
    "        ) # 3. Calculate Loss Function\n",
    "\n",
    "        optimizer.zero_grad() # 4A. Zero out the gradients\n",
    "        loss.backward() # 4B. Calculate the gradients\n",
    "        optimizer.step() # 5. Update the weights\n",
    "\n",
    "        total_loss_per_epoch += loss.item()\n",
    "        total_correct_per_epoch += predictions.argmax(dim=1).eq(labels).sum().item()\n",
    "        # 6. Iterate over all batches from the dataset\n",
    "\n",
    "    print(\n",
    "        'Epoch:', epoch,\n",
    "        '\\nTotal_correct:', total_correct_per_epoch,\n",
    "        '\\nTotal_loss:', total_loss_per_epoch,\n",
    "        '\\nAccuracy:', total_correct_per_epoch/len(train_set)\n",
    "    )\n",
    "    tb.add_scalar('Loss', total_loss_per_epoch, epoch)\n",
    "    tb.add_scalar('Correct', total_correct_per_epoch, epoch)\n",
    "    tb.add_scalar('Accuracy', total_correct_per_epoch/len(train_set))\n",
    "\n",
    "    tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\n",
    "    tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\n",
    "    tb.add_histogram('conv1.weight.grad', network.conv1.weight.grad, epoch)\n",
    "    # 7. Iterate through next epochs until the loss function is minimized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "tb.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}