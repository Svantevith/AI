{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from network import Network"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating Variables For Our Hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "shuffle=True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "network = Network()\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=network.parameters(),\n",
    "    lr=learning_rate\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "tb = SummaryWriter(comment=f'batch_size={batch_size} lr={learning_rate}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate Loss With Different Batch Sizes\n",
    "Since we'll be varying our batch sizes now, we'll need to make a change to the way we are calculating and accumulating\n",
    "the loss. Instead of just summing the loss returned by the loss function. We'll adjust it to account for the batch size.\n",
    "\n",
    "    total_loss += loss.item() * batch_size\n",
    "\n",
    "Why do this? The cross_entropy loss function averages the loss values that are produced by the batch and then returns\n",
    "this average loss. This is why we need to account for the batch size.\n",
    "\n",
    "There is a parameter that the cross_entropy function accepts called reduction that we could also use.\n",
    "\n",
    "The reduction parameter optionally accepts a string as an argument. This parameter specifies the reduction to apply to\n",
    "the output of the loss function.\n",
    "    1.  'none' - no reduction will be applied.\n",
    "    2.  'mean' - the sum of the output will be divided by the number of elements in the output.\n",
    "    3.  'sum' - the output will be summed.\n",
    "\n",
    "  Note that the default is 'mean'. This is why loss.item() * batch_size works."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experimenting With Hyperparameter Values\n",
    "All we need to do is create some lists and some loops, and we can run the code and sit back and wait for all the\n",
    "combinations to run."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameter Lists"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "batch_size_list = [10, 100, 1000, 10000]\n",
    "learning_rate_list = [0.01, 0.001, 0.0001, 0.00001]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1,\n",
      "Loss: 38609.35492885299,\n",
      "Correct: 45213,\n",
      "Accuracy: 0.75355\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 33503.85079354048,\n",
      "Correct: 47448,\n",
      "Accuracy: 0.7908\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 33265.30728791375,\n",
      "Correct: 47552,\n",
      "Accuracy: 0.7925333333333333\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 32964.24246055074,\n",
      "Correct: 47606,\n",
      "Accuracy: 0.7934333333333333\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 32869.254753100686,\n",
      "Correct: 47877,\n",
      "Accuracy: 0.79795\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 34610.122762969695,\n",
      "Correct: 46954,\n",
      "Accuracy: 0.7825666666666666\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 23130.320638203993,\n",
      "Correct: 51441,\n",
      "Accuracy: 0.85735\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 20049.986519434024,\n",
      "Correct: 52562,\n",
      "Accuracy: 0.8760333333333333\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 18439.105176299345,\n",
      "Correct: 53104,\n",
      "Accuracy: 0.8850666666666667\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 17286.888727564365,\n",
      "Correct: 53593,\n",
      "Accuracy: 0.8932166666666667\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 50552.06475857645,\n",
      "Correct: 41166,\n",
      "Accuracy: 0.6861\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 35434.13332019001,\n",
      "Correct: 46255,\n",
      "Accuracy: 0.7709166666666667\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 31554.784537684172,\n",
      "Correct: 47791,\n",
      "Accuracy: 0.7965166666666667\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 28903.669766848907,\n",
      "Correct: 48998,\n",
      "Accuracy: 0.8166333333333333\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 26878.715385543182,\n",
      "Correct: 49989,\n",
      "Accuracy: 0.83315\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 105222.86479234695,\n",
      "Correct: 22504,\n",
      "Accuracy: 0.37506666666666666\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 61108.11402261257,\n",
      "Correct: 36942,\n",
      "Accuracy: 0.6157\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 53242.102918475866,\n",
      "Correct: 40080,\n",
      "Accuracy: 0.668\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 49027.9350823164,\n",
      "Correct: 41794,\n",
      "Accuracy: 0.6965666666666667\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 46183.74550703913,\n",
      "Correct: 42909,\n",
      "Accuracy: 0.71515\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 33140.558221936226,\n",
      "Correct: 47484,\n",
      "Accuracy: 0.7914\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 22850.794188678265,\n",
      "Correct: 51498,\n",
      "Accuracy: 0.8583\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 21125.24664849043,\n",
      "Correct: 52154,\n",
      "Accuracy: 0.8692333333333333\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 19922.14219123125,\n",
      "Correct: 52601,\n",
      "Accuracy: 0.8766833333333334\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 19492.714804410934,\n",
      "Correct: 52777,\n",
      "Accuracy: 0.8796166666666667\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 44113.98759186268,\n",
      "Correct: 43491,\n",
      "Accuracy: 0.72485\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 26453.300638496876,\n",
      "Correct: 50292,\n",
      "Accuracy: 0.8382\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 22690.642458200455,\n",
      "Correct: 51758,\n",
      "Accuracy: 0.8626333333333334\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 20820.346769690514,\n",
      "Correct: 52379,\n",
      "Accuracy: 0.8729833333333333\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 19575.153978168964,\n",
      "Correct: 52829,\n",
      "Accuracy: 0.8804833333333333\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 84398.89520406723,\n",
      "Correct: 31403,\n",
      "Accuracy: 0.5233833333333333\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 48343.11117529869,\n",
      "Correct: 42358,\n",
      "Accuracy: 0.7059666666666666\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 42022.23238945007,\n",
      "Correct: 44053,\n",
      "Accuracy: 0.7342166666666666\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 38924.02202486992,\n",
      "Correct: 45067,\n",
      "Accuracy: 0.7511166666666667\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 36937.7591252327,\n",
      "Correct: 45840,\n",
      "Accuracy: 0.764\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 137777.46167182922,\n",
      "Correct: 12451,\n",
      "Accuracy: 0.20751666666666665\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 132141.1975622177,\n",
      "Correct: 22802,\n",
      "Accuracy: 0.38003333333333333\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 110140.29873609543,\n",
      "Correct: 27728,\n",
      "Accuracy: 0.46213333333333334\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 83920.75698375702,\n",
      "Correct: 33826,\n",
      "Accuracy: 0.5637666666666666\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 69993.80518198013,\n",
      "Correct: 36955,\n",
      "Accuracy: 0.6159166666666667\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 63844.78706121445,\n",
      "Correct: 35761,\n",
      "Accuracy: 0.5960166666666666\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 33968.12364459038,\n",
      "Correct: 47234,\n",
      "Accuracy: 0.7872333333333333\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 28530.75048327446,\n",
      "Correct: 49565,\n",
      "Accuracy: 0.8260833333333333\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 25623.093008995056,\n",
      "Correct: 50639,\n",
      "Accuracy: 0.8439833333333333\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 23774.932295084,\n",
      "Correct: 51322,\n",
      "Accuracy: 0.8553666666666667\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 92422.14143276215,\n",
      "Correct: 29075,\n",
      "Accuracy: 0.4845833333333333\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 46025.35283565521,\n",
      "Correct: 42689,\n",
      "Accuracy: 0.7114833333333334\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 39743.404507637024,\n",
      "Correct: 44906,\n",
      "Accuracy: 0.7484333333333333\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 36312.15542554855,\n",
      "Correct: 46189,\n",
      "Accuracy: 0.7698166666666667\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 34167.180836200714,\n",
      "Correct: 47045,\n",
      "Accuracy: 0.7840833333333334\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 137809.97109413147,\n",
      "Correct: 8083,\n",
      "Accuracy: 0.13471666666666668\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 132252.5827884674,\n",
      "Correct: 17355,\n",
      "Accuracy: 0.28925\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 107287.44411468506,\n",
      "Correct: 28763,\n",
      "Accuracy: 0.47938333333333333\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 74844.07985210419,\n",
      "Correct: 36296,\n",
      "Accuracy: 0.6049333333333333\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 61006.679475307465,\n",
      "Correct: 38675,\n",
      "Accuracy: 0.6445833333333333\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 138207.6768875122,\n",
      "Correct: 7962,\n",
      "Accuracy: 0.1327\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 138078.88340950012,\n",
      "Correct: 10079,\n",
      "Accuracy: 0.16798333333333335\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 137895.82014083862,\n",
      "Correct: 11187,\n",
      "Accuracy: 0.18645\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 137655.28535842896,\n",
      "Correct: 12143,\n",
      "Accuracy: 0.20238333333333333\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 137348.6132621765,\n",
      "Correct: 14734,\n",
      "Accuracy: 0.24556666666666666\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 128172.96385765076,\n",
      "Correct: 12381,\n",
      "Accuracy: 0.20635\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 87970.88384628296,\n",
      "Correct: 24530,\n",
      "Accuracy: 0.4088333333333333\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 64845.98457813263,\n",
      "Correct: 33052,\n",
      "Accuracy: 0.5508666666666666\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 55233.609676361084,\n",
      "Correct: 38705,\n",
      "Accuracy: 0.6450833333333333\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 51322.529315948486,\n",
      "Correct: 39757,\n",
      "Accuracy: 0.6626166666666666\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 137363.4672164917,\n",
      "Correct: 13096,\n",
      "Accuracy: 0.21826666666666666\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 133265.25211334229,\n",
      "Correct: 16243,\n",
      "Accuracy: 0.27071666666666666\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 122193.88246536255,\n",
      "Correct: 25856,\n",
      "Accuracy: 0.43093333333333333\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 101278.11312675476,\n",
      "Correct: 31754,\n",
      "Accuracy: 0.5292333333333333\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 78028.92923355103,\n",
      "Correct: 36624,\n",
      "Accuracy: 0.6104\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 138239.3455505371,\n",
      "Correct: 6000,\n",
      "Accuracy: 0.1\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 138091.28046035767,\n",
      "Correct: 6000,\n",
      "Accuracy: 0.1\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 137941.51067733765,\n",
      "Correct: 6000,\n",
      "Accuracy: 0.1\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 137769.1102027893,\n",
      "Correct: 6000,\n",
      "Accuracy: 0.1\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 137556.17380142212,\n",
      "Correct: 6000,\n",
      "Accuracy: 0.1\n",
      "\n",
      "Epoch: 1,\n",
      "Loss: 138407.79066085815,\n",
      "Correct: 6000,\n",
      "Accuracy: 0.1\n",
      "\n",
      "Epoch: 2,\n",
      "Loss: 138390.94161987305,\n",
      "Correct: 6000,\n",
      "Accuracy: 0.1\n",
      "\n",
      "Epoch: 3,\n",
      "Loss: 138374.20225143433,\n",
      "Correct: 6000,\n",
      "Accuracy: 0.1\n",
      "\n",
      "Epoch: 4,\n",
      "Loss: 138357.4628829956,\n",
      "Correct: 6000,\n",
      "Accuracy: 0.1\n",
      "\n",
      "Epoch: 5,\n",
      "Loss: 138340.51609039307,\n",
      "Correct: 6000,\n",
      "Accuracy: 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch_size in batch_size_list:\n",
    "    for learning_rate in learning_rate_list:\n",
    "        optimizer = torch.optim.Adam(\n",
    "            params=network.parameters(),\n",
    "            lr=learning_rate\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "        images, labels = next(\n",
    "            iter(train_loader)\n",
    "        )\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        comment = f'batch_size={batch_size} lr={learning_rate}'\n",
    "        tb = SummaryWriter(comment=comment)\n",
    "        tb.add_image('images', grid)\n",
    "        tb.add_graph(network, images)\n",
    "\n",
    "        for epoch in range(5):\n",
    "            total_loss_per_epoch = 0\n",
    "            total_correct_per_epoch = 0\n",
    "            accuracy_per_epoch = 0\n",
    "            for batch in train_loader:\n",
    "                images, labels = batch # 1. Get Batch\n",
    "                predictions = network(images) # 2. Pass Batch to Network\n",
    "\n",
    "                loss = torch.nn.functional.cross_entropy(\n",
    "                    input=predictions,\n",
    "                    target=labels,\n",
    "                ) # 3. Calculate loss function\n",
    "\n",
    "                optimizer.zero_grad() # 4A. Zero out the Gradients\n",
    "                loss.backward() # 4B. Calculate the Gradients\n",
    "                optimizer.step() # 5. Update the Weights\n",
    "\n",
    "                total_loss_per_epoch += loss.item() * batch_size\n",
    "                total_correct_per_epoch += predictions.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "            accuracy_per_epoch =  total_correct_per_epoch / len(train_set)\n",
    "            tb.add_scalar('Loss', total_loss_per_epoch, epoch)\n",
    "            tb.add_scalar('Correct', total_correct_per_epoch, epoch)\n",
    "            tb.add_scalar('Accuracy', accuracy_per_epoch, epoch)\n",
    "\n",
    "            for name, param in network.named_parameters():\n",
    "                tb.add_histogram(name, param, epoch)\n",
    "\n",
    "            print('Epoch: {},'\n",
    "                  '\\nLoss: {},'\n",
    "                  '\\nCorrect: {},'\n",
    "                  '\\nAccuracy: {}'\n",
    "                  '\\n'.format(\n",
    "                epoch+1, total_loss_per_epoch, total_correct_per_epoch, accuracy_per_epoch\n",
    "                  )\n",
    "            )\n",
    "\n",
    "        tb.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adding More Hyperparameters Without Nesting\n",
    "There is a solution. We can create a set of parameters for each run, and package all of them up in a single iterable.\n",
    "\n",
    "If we have a list of parameters, we can package them up into a set for each of our runs using the Cartesian product.\n",
    "For this we'll use the product function from the itertools library."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from itertools import product"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "shuffle = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    learning_rate: [0.01, 0.001],\n",
    "    batch_size: [100, 1000],\n",
    "    shuffle: [True, False]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "param_values = [value for value in parameters.values()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 100 True\n",
      "0.01 100 False\n",
      "0.01 1000 True\n",
      "0.01 1000 False\n",
      "0.001 100 True\n",
      "0.001 100 False\n",
      "0.001 1000 True\n",
      "0.001 1000 False\n"
     ]
    }
   ],
   "source": [
    "for learning_rate, batch_size, shuffle in product(*param_values):\n",
    "    print(learning_rate, batch_size, shuffle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-20-1c7c44eeedd1>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m             \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 30\u001B[1;33m             \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     31\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\PythonGPU\\lib\\site-packages\\torch\\tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[0;32m    183\u001B[0m                 \u001B[0mproducts\u001B[0m\u001B[1;33m.\u001B[0m \u001B[0mDefaults\u001B[0m \u001B[0mto\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    184\u001B[0m         \"\"\"\n\u001B[1;32m--> 185\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    186\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    187\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\PythonGPU\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[0;32m    119\u001B[0m         \u001B[0mgrad_tensors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgrad_tensors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 121\u001B[1;33m     \u001B[0mgrad_tensors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_make_grads\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    122\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mretain_graph\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    123\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\PythonGPU\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36m_make_grads\u001B[1;34m(outputs, grads)\u001B[0m\n\u001B[0;32m     45\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrequires_grad\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 47\u001B[1;33m                     \u001B[1;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"grad can be implicitly created only for scalar outputs\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     48\u001B[0m                 \u001B[0mnew_grads\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mones_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmemory_format\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreserve_format\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "for learning_rate, batch_size, shuffle in product(*param_values):\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    network = Network()\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=network.parameters(),\n",
    "        lr=learning_rate\n",
    "    )\n",
    "\n",
    "    images, labels = next(iter(train_loader))\n",
    "\n",
    "    comment = f'batch_size {batch_size} lr {learning_rate} shuffle {shuffle}'\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "    tb.add_image('images', grid)\n",
    "    tb.add_graph(network, images)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        total_loss_per_epoch = 0\n",
    "        total_correct_per_epoch = 0\n",
    "        accuracy_per_epoch = 0\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch # 1. Get Batch\n",
    "            predictions = network(images) # 2. Pass Images into Network\n",
    "\n",
    "            loss = torch.nn.functional.cross_entropy(\n",
    "                input=predictions,\n",
    "                target=labels,\n",
    "                reduction='mean'\n",
    "            ) # 3. Calculate Loss Function\n",
    "\n",
    "            optimizer.zero_grad() # 4A. Zero out the Gradients\n",
    "            loss.backward() # 4B. Calculate Gradients\n",
    "            optimizer.step() # 5. Update the weights\n",
    "\n",
    "            total_loss_per_epoch += loss.item() * batch_size\n",
    "            # * batch_size or images.shape[0], to be more accurate, because we use different batch sizes and we are\n",
    "            # using the cross_entropy.reduction='mean' (scalar)!\n",
    "            total_correct_per_epoch += predictions.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "        accuracy_per_epoch = total_correct_per_epoch / len(train_set)\n",
    "\n",
    "        tb.add_scalar('Loss', total_loss_per_epoch, epoch)\n",
    "        tb.add_scalar('Correct', total_correct_per_epoch, epoch)\n",
    "        tb.add_scalar('Accuracy', accuracy_per_epoch, epoch)\n",
    "\n",
    "        for name, param in network.named_parameters():\n",
    "            tb.add_histogram(name, param, epoch)\n",
    "            tb.add_histogram(f'{name}.grad', param.grad, epoch)\n",
    "\n",
    "        print('Epoch: {}, '\n",
    "              '\\nLoss: {},'\n",
    "              '\\nAccuracy: {}'.format(\n",
    "            epoch + 1,\n",
    "            total_loss_per_epoch,\n",
    "            accuracy_per_epoch\n",
    "              ))\n",
    "\n",
    "    tb.close() # tb.close() after all epochs!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using The RunBuilder Class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from collections import OrderedDict, namedtuple\n",
    "from itertools import product"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This product() function is the one we saw last time that computes a Cartesian product given multiple list inputs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class RunBuilder:\n",
    "    @staticmethod\n",
    "    def get_runs(param_dict):\n",
    "\n",
    "        Run = namedtuple('Run', param_dict.keys())\n",
    "        runs = []\n",
    "        for values in product(*param_dict.values()):\n",
    "            runs.append(\n",
    "                Run(*values)\n",
    "            )\n",
    "\n",
    "        return runs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "params = OrderedDict(\n",
    "    learning_rate = [.01, 0.0001],\n",
    "    batch_size = [100, 1000],\n",
    "    # shuffle = [True, False]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "runs = RunBuilder.get_runs(params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run(learning_rate=0.01, batch_size=100, shuffle=True), Run(learning_rate=0.01, batch_size=100, shuffle=False), Run(learning_rate=0.01, batch_size=1000, shuffle=True), Run(learning_rate=0.01, batch_size=1000, shuffle=False), Run(learning_rate=0.0001, batch_size=100, shuffle=True), Run(learning_rate=0.0001, batch_size=100, shuffle=False), Run(learning_rate=0.0001, batch_size=1000, shuffle=True), Run(learning_rate=0.0001, batch_size=1000, shuffle=False)]\n"
     ]
    }
   ],
   "source": [
    "print(runs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First run: Run(learning_rate=0.01, batch_size=100, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "print('First run:', runs[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['learning_rate', 'batch_size', 'shuffle'])\n",
      "odict_values([[0.01, 0.0001], [100, 1000], [True, False]])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    params.keys()\n",
    ")\n",
    "print(params.values())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before:\n",
    "\n",
    "    for lr, batch_size, shuffle in product(*param_values):\n",
    "        comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle}'\n",
    "        # Training process given the set of parameters\n",
    "\n",
    "After:\n",
    "\n",
    "    for run in Runbuilder.get_runs(params):\n",
    "        comment = f'-{run}'\n",
    "         # Training process given the set of parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 32700.03606379032, Accuracy: 0.7940333333333334\n",
      "\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.09 MiB for an array with shape (392, 242, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-35-b2db79c8d59f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     25\u001B[0m             \u001B[0mgrid\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake_grid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m             \u001B[0mtb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_image\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'images'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m             \u001B[0mtb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnetwork\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimages\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\PythonGPU\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py\u001B[0m in \u001B[0;36madd_image\u001B[1;34m(self, tag, img_tensor, global_step, walltime, dataformats)\u001B[0m\n\u001B[0;32m    538\u001B[0m             \u001B[0mimg_tensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mworkspace\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mFetchBlob\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg_tensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    539\u001B[0m         self._get_file_writer().add_summary(\n\u001B[1;32m--> 540\u001B[1;33m             image(tag, img_tensor, dataformats=dataformats), global_step, walltime)\n\u001B[0m\u001B[0;32m    541\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    542\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0madd_images\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtag\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimg_tensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mglobal_step\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwalltime\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataformats\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'NCHW'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\PythonGPU\\lib\\site-packages\\torch\\utils\\tensorboard\\summary.py\u001B[0m in \u001B[0;36mimage\u001B[1;34m(tag, tensor, rescale, dataformats)\u001B[0m\n\u001B[0;32m    312\u001B[0m     \u001B[0mscale_factor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_calc_scale_factor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m     \u001B[0mtensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtensor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 314\u001B[1;33m     \u001B[0mtensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mscale_factor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muint8\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    315\u001B[0m     \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmake_image\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrescale\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mrescale\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    316\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mSummary\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mSummary\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mValue\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtag\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtag\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimage\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 1.09 MiB for an array with shape (392, 242, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "for run in RunBuilder.get_runs(params):\n",
    "    network = Network()\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True # drops last batch if the size of last batch differs from other\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=network.parameters(),\n",
    "        lr=learning_rate\n",
    "    )\n",
    "    \n",
    "    images, labels = next(iter(train_loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "    comment = f'-{run}'\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    tb.add_image('images', grid)\n",
    "    tb.add_graph(network, images)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        total_loss_per_epoch = 0\n",
    "        total_correct_per_epoch = 0\n",
    "        accuracy_per_epoch = 0\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch\n",
    "            predictions = network(images)\n",
    "            loss = torch.nn.functional.cross_entropy(\n",
    "                input=predictions,\n",
    "                target=labels,\n",
    "                reduction='mean'\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss_per_epoch += loss.item() * batch_size\n",
    "            total_correct_per_epoch += predictions.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "        accuracy_per_epoch = total_correct_per_epoch / len(train_set)\n",
    "\n",
    "        tb.add_scalar('loss', total_loss_per_epoch, epoch)\n",
    "        tb.add_scalar('correct', total_correct_per_epoch, epoch)\n",
    "        tb.add_scalar('accuracy', accuracy_per_epoch, epoch)\n",
    "\n",
    "        for name, param in network.named_parameters():\n",
    "            tb.add_histogram(name, param, epoch)\n",
    "            tb.add_histogram(f'{name}.grad', param.grad, epoch)\n",
    "\n",
    "        print(f'Epoch: {epoch}, '\n",
    "              f'Loss: {total_loss_per_epoch}, '\n",
    "              f'Accuracy: {accuracy_per_epoch}\\n')\n",
    "\n",
    "    tb.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}