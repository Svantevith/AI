{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipelines\n",
    "Pipelines are a simple way to keep your data preprocessing and modeling code organized. Specifically, a pipeline\n",
    "bundles preprocessing and modeling steps so you can use the whole bundle as if it were a single step.\n",
    "\n",
    "Many data scientists hack together models without pipelines, but pipelines have some important benefits. Those include:\n",
    "\n",
    "    1.  Cleaner Code: Accounting for data at each step of preprocessing can get messy. With a pipeline, you won't need\n",
    "    to manually keep track of your training and validation data at each step.\n",
    "    2.  Fewer Bugs: There are fewer opportunities to misapply a step or forget a preprocessing step.\n",
    "    3.  Easier to Productionize: It can be surprisingly hard to transition a model from a prototype to something\n",
    "    deployable at scale. We won't go into the many related concerns here, but pipelines can help.\n",
    "    4.  More Options for Model Validation: You will see an example in the next tutorial, which covers cross-validation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [],
   "source": [
    "melbourne_df = pd.read_csv('data/Melbourne_housing_FULL.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove rows with missing target, separate target from predictors, put None instead of Nan."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Suburb             Address  Rooms Type      Price Method SellerG  \\\n",
      "0  Abbotsford       68 Studley St      2    h        NaN     SS  Jellis   \n",
      "1  Abbotsford        85 Turner St      2    h  1480000.0      S  Biggin   \n",
      "2  Abbotsford     25 Bloomburg St      2    h  1035000.0      S  Biggin   \n",
      "3  Abbotsford  18/659 Victoria St      3    u        NaN     VB  Rounds   \n",
      "4  Abbotsford        5 Charles St      3    h  1465000.0     SP  Biggin   \n",
      "\n",
      "        Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n",
      "0  3/09/2016       2.5    3067.0  ...       1.0  1.0     126.0           NaN   \n",
      "1  3/12/2016       2.5    3067.0  ...       1.0  1.0     202.0           NaN   \n",
      "2  4/02/2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n",
      "3  4/02/2016       2.5    3067.0  ...       2.0  1.0       0.0           NaN   \n",
      "4  4/03/2017       2.5    3067.0  ...       2.0  0.0     134.0         150.0   \n",
      "\n",
      "   YearBuilt         CouncilArea Lattitude  Longtitude             Regionname  \\\n",
      "0        NaN  Yarra City Council  -37.8014    144.9958  Northern Metropolitan   \n",
      "1        NaN  Yarra City Council  -37.7996    144.9984  Northern Metropolitan   \n",
      "2     1900.0  Yarra City Council  -37.8079    144.9934  Northern Metropolitan   \n",
      "3        NaN  Yarra City Council  -37.8114    145.0116  Northern Metropolitan   \n",
      "4     1900.0  Yarra City Council  -37.8093    144.9944  Northern Metropolitan   \n",
      "\n",
      "  Propertycount  \n",
      "0        4019.0  \n",
      "1        4019.0  \n",
      "2        4019.0  \n",
      "3        4019.0  \n",
      "4        4019.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(melbourne_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the first step we use the target column as the pivot, in reference we drop other rows to.\n",
    "\n",
    "Subset parameter limits the dropping process to the columns passed as parameter. Dropna(subset=['Price']) will drop\n",
    "ONLY the rows corresponding to NaN's found ONLY in Price column.\n",
    "\n",
    "Basically we want to clean the original DataFrame (drop rows) in respect to the Price column.\n",
    "\n",
    "We should clean up the DataFrame in respect to the target data (drop rows corresponding to NaN's in target column),\n",
    "because the features data will be imputed and one-hot-encoded in further steps.\n",
    "\n",
    "Inplace means that the changes are done on DataFrame itself. It is impossible to assign new_df = df.drop(inplace=True),\n",
    "if inplace is set to True."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "outputs": [],
   "source": [
    "melbourne_df.dropna(axis=0, subset=['Price'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set feature matrix X to the DataFrame except Price column and target array y to Price."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "outputs": [],
   "source": [
    "X = melbourne_df.drop(['Price'], axis=1, inplace=False)\n",
    "y = melbourne_df['Price']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=37)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cardinality is defined as number of unique categorical values in a column.\n",
    "\n",
    "We need to select the Low Cardinality Columns (number of unique labels <= 15), it is convenient but arbitrary.\n",
    "\n",
    "Numerical columns are all numerical columns except Price.\n",
    "Categorical columns are all categorical columns.\n",
    "Features are numerical + categorical columns (except Price!)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "outputs": [],
   "source": [
    "numerical_columns = [col for col in X if is_numeric_dtype(melbourne_df[col])]\n",
    "categorical_columns = [col for col in X if not is_numeric_dtype(melbourne_df[col])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Suburb': 345, 'Address': 26751, 'Type': 3, 'Method': 5, 'SellerG': 349, 'Date': 78, 'CouncilArea': 33, 'Regionname': 8}\n"
     ]
    }
   ],
   "source": [
    "frequency_labels = {col: X[col].nunique() for col in X[categorical_columns].columns}\n",
    "print(frequency_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Type', 'Method', 'Regionname']\n"
     ]
    }
   ],
   "source": [
    "low_cardinality_columns = [col for col in X[categorical_columns] if X[col].nunique() <= 15]\n",
    "print(low_cardinality_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We need to leave only the categorical columns with low cardinality.\n",
    "\n",
    "Remember to copy during assignment, not to pass the objects by reference!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "outputs": [],
   "source": [
    "feature_columns = numerical_columns + low_cardinality_columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "outputs": [],
   "source": [
    "X_train = X_train[feature_columns].copy()\n",
    "X_test = X_test[feature_columns].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1: Define Preprocessing Steps\n",
    "Similar to how a pipeline bundles together preprocessing and modeling steps, we use the ColumnTransformer class to\n",
    "bundle together different preprocessing steps. The code below:\n",
    "\n",
    "    1.  imputes missing values in numerical data, and\n",
    "    2.  imputes missing values and applies a one-hot encoding to categorical data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocessing for numerical data (using SimpleImputer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "outputs": [],
   "source": [
    "numerical_transformer = SimpleImputer(strategy='constant')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocessing for categorical data (using SimpleImputer and OneHotEncoder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bundle preprocessing for numerical and categorical data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_transformer, numerical_columns),\n",
    "        ('categorical', categorical_transformer, low_cardinality_columns)\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2: Define The Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "outputs": [],
   "source": [
    "melbourne_model = RandomForestRegressor(n_estimators=150, random_state=37)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3: Create and Evaluate the Pipeline\n",
    "Finally, we use the Pipeline class to define a pipeline that bundles the preprocessing and modeling steps. There are a\n",
    "few important things to notice:\n",
    "\n",
    "    With the pipeline, we preprocess the training data and fit the model in a single line of code. (In contrast,\n",
    "    without a pipeline, we have to do imputation, one-hot encoding, and model training in separate steps. This becomes\n",
    "    especially messy if we have to deal with both numerical and categorical variables!)\n",
    "\n",
    "    With the pipeline, we supply the unprocessed features in X_valid to the predict() command, and the pipeline\n",
    "    automatically preprocesses the features before generating predictions. (However, without a pipeline, we have to\n",
    "    remember to preprocess the validation data before making predictions.)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [],
   "source": [
    "my_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', melbourne_model)\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('numerical',\n                                                  SimpleImputer(strategy='constant'),\n                                                  ['Rooms', 'Distance',\n                                                   'Postcode', 'Bedroom2',\n                                                   'Bathroom', 'Car',\n                                                   'Landsize', 'BuildingArea',\n                                                   'YearBuilt', 'Lattitude',\n                                                   'Longtitude',\n                                                   'Propertycount']),\n                                                 ('categorical',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('one_hot_encoder',\n                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n                                                  ['Type', 'Method',\n                                                   'Regionname'])])),\n                ('model',\n                 RandomForestRegressor(n_estimators=150, random_state=37))])"
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pipeline.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "outputs": [],
   "source": [
    "y_pred = my_pipeline.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:\n",
      " 168200.83781076694\n"
     ]
    }
   ],
   "source": [
    "score = mean_absolute_error(y_test, y_pred)\n",
    "print('Mean Absolute Error:\\n', score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}